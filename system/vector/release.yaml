---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: vector
spec:
  interval: 1m
  releaseName: vector
  chart:
    spec:
      chart: vector
      version: 0.50.0
      sourceRef:
        kind: HelmRepository
        name: vector
      interval: 1m
  install:
    remediation:
      retries: 5

  values:
    role: Agent
    podMonitor:
      enabled: true
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    extraVolumes:
    - name: gcp-data-hub-project-log-shipping
      secret:
        secretName: gcp-data-hub-project-log-shipping
    extraVolumeMounts:
    - name: gcp-data-hub-project-log-shipping
      mountPath: /etc/gcp-data-hub-project-log-shipping
      readOnly: true
    env:
      - name: VECTOR_LOG
        value: info
    tolerations:
    - effect: NoSchedule
      operator: Exists
    customConfig:
      data_dir: /vector-data-dir
      api:
        enabled: true
        address: 127.0.0.1:8686
        playground: false
      sources:
        logs:
          type: kubernetes_logs
          insert_namespace_fields: false
          pod_annotation_fields:
            container_id: ""
            container_image_id: ""
            pod_uid: ""
            pod_annotations: ""
          namespace_annotation_fields:
            namespace_labels: ""
        host_metrics:
          filesystem:
            devices:
              excludes: [binfmt_misc]
            filesystems:
              excludes: [binfmt_misc]
            mountPoints:
              excludes: ["*/proc/sys/fs/binfmt_misc"]
          type: host_metrics
        internal_metrics:
          type: internal_metrics
        traefik_logs:
          type: kubernetes_logs
          extra_label_selector: app.kubernetes.io/name==traefik
      transforms:
        filter_node_labels:
          type: remap
          inputs:
            - logs
          source: |
            if exists(.kubernetes.node_labels) {
              allowed_labels = [
                "elifesciences.org/project",
                "karpenter.sh/capacity-type",
                "karpenter.sh/nodepool",
                "kubernetes.io/arch",
                "kubernetes.io/hostname",
                "node.kubernetes.io/instance-type",
                "topology.kubernetes.io/zone",
                "type"
              ]
              .kubernetes.node_labels = filter(object!(.kubernetes.node_labels)) -> |key, value| { includes(allowed_labels, key) }
            }
        traefik_json_parse:
          type: remap
          inputs:
            - traefik_logs
          source: |
            json, err = parse_json(.message)
            if err != null {
              abort
            }
            . = json
        traefik_json_parse2:
          type: remap
          inputs:
            - traefik_logs
          source: |
            # Parse the initial k8s log wrapper
            raw, err = parse_json(.message)
            if err != null { abort }

            # Create the httpRequest object to match GCP/Nginx format
            .httpRequest.requestMethod = raw.RequestMethod
            .httpRequest.requestUrl = (string(raw.RequestHost) ?? "") + (string(raw.RequestPath) ?? "")
            .httpRequest.status = to_int(raw.DownstreamStatus) ?? 0
            .httpRequest.requestSize = to_string(raw.RequestContentSize) ?? "0"
            .httpRequest.responseSize = to_string(raw.DownstreamContentSize) ?? "0"
            .httpRequest.userAgent = raw."request_User-Agent"
            .httpRequest.remoteIp = raw.ClientHost
            .httpRequest.referer = raw."request_Referer"

            # Convert nanoseconds to "X.Y s" format
            if exists(raw.Duration) {
              .httpRequest.latency = to_string(to_float(raw.Duration) / 1000000000) + " s"
            }

            .httpRequest.protocol = raw.RequestProtocol
            .httpRequest.xForwardedFor = raw."request_X-Forwarded-For"
            .httpRequest.xForwardedHost = raw."request_X-Forwarded-Host"
            .httpRequest.xOriginalForwardedFor = raw."request_X-Original-Forwarded-For"
            .httpRequest.xJA4Fingerprint = raw."request_x-ja4fingerprint"

            # Map Top Level Fields
            .requestID = raw."request_X-Request-ID"
            .proxyUpstreamName = raw.ServiceName
            .upstreamAddr = raw.ServiceAddr
            .upstreamStatus = to_string(raw.OriginStatus) ?? ""
            .timestamp = raw.StartUTC

            # Helper fields for proxy info
            .proxyProtocolAddr = raw.ClientHost
            .proxyProtocolPort = raw.ClientPort
        filter_traefik_podinfo:
          type: filter
          inputs:
            - traefik_json_parse
          condition: |
            starts_with(string(.RequestAddr) ?? "", "podinfo.flux-test.elifesciences.org")
        filter_traefik_podinfo2:
          type: filter
          inputs:
            - traefik_json_parse2
          condition: |
            starts_with(string(.httpRequest.requestUrl) ?? "", "podinfo.flux-test.elifesciences.org")
      sinks:
        prom_exporter:
          type: prometheus_exporter
          inputs: [host_metrics, internal_metrics]
          address: 0.0.0.0:9090
        flux_test_podinfo_gcp:
          type: gcp_cloud_storage
          inputs:
            - filter_traefik_podinfo
          bucket: elife-cluster-logs
          credentials_path: /etc/gcp-data-hub-project-log-shipping/credentials.json
          key_prefix: ${cluster_name}/podinfo/dt=%F/
          filename_extension: jsonl
          encoding:
            codec: native_json
        flux_test_podinfo_gcp2:
          type: gcp_cloud_storage
          inputs:
            - filter_traefik_podinfo2
          bucket: elife-cluster-logs
          credentials_path: /etc/gcp-data-hub-project-log-shipping/credentials.json
          key_prefix: ${cluster_name}/podinfo2/dt=%F/
          filename_extension: jsonl
          encoding:
            codec: native_json
        local_victorialogs:
          inputs:
          - filter_node_labels
          type: elasticsearch
          endpoints:
          - "http://victorialogs-victoria-logs-single-server.victorialogs:9428/insert/elasticsearch/"
          mode: "bulk"
          api_version: "v8"
          healthcheck:
            enabled: false
          query:
            _msg_field: "message"
            _time_field: "timestamp"
            _stream_fields: "kubernetes.pod_namespace,kubernetes.container_name"
